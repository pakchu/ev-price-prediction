{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from optuna.trial import Trial\n",
    "from sklearn.model_selection import KFold\n",
    "import time, pickle, os\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (21, 9)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS=[\n",
    "    'manufacturer',\n",
    "    'model',\n",
    "    'vehicle_condition',\n",
    "    'battery_capacity',\n",
    "    'drivetrain',\n",
    "    'mileage',\n",
    "    'warranty_period',\n",
    "    'accident_history',\n",
    "    'year_of_manufacture',\n",
    "]\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "train = train.drop(columns=['ID'])\n",
    "train.columns = COLUMNS + ['y']\n",
    "train.manufacturer = train.manufacturer.str.replace('사', '_corp')\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "test = test.drop(columns=['ID'])\n",
    "test.columns = COLUMNS\n",
    "test_X = test\n",
    "test_X.manufacturer = test_X.manufacturer.str.replace('사', '_corp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['battery_capacity'] = train['battery_capacity'].fillna(0)\n",
    "test['battery_capacity'] = test['battery_capacity'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x_scaler = StandardScaler()\n",
    "# y_scaler = StandardScaler()\n",
    "\n",
    "# select numerical columns\n",
    "x_scaler.fit(train[train.select_dtypes(include='number').columns.drop('y')])\n",
    "train.loc[:, train.select_dtypes(include='number').columns.drop('y')] = x_scaler.transform(train[train.select_dtypes(include='number').columns.drop('y')])\n",
    "# train.loc[:, 'y'] = y_scaler.fit_transform(train[['y']])\n",
    "test.loc[:, test.select_dtypes(include='number').columns] = x_scaler.transform(test[test.select_dtypes(include='number').columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train,test], axis=0, ignore_index=True)\n",
    "FEATURES = combined.columns.drop(\"y\")\n",
    "CATS = []\n",
    "HIGH_CARDINALITY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE 9 BASIC FEATURES ARE:\n",
      "manufacturer (categorical) with 7 unique values\n",
      "model (categorical) with 21 unique values\n",
      "vehicle_condition (categorical) with 3 unique values\n",
      "battery_capacity (numerical) with 203 unique values\n",
      "drivetrain (categorical) with 3 unique values\n",
      "mileage (numerical) with 7633 unique values\n",
      "warranty_period (numerical) with 11 unique values\n",
      "accident_history (categorical) with 2 unique values\n",
      "year_of_manufacture (numerical) with 3 unique values\n"
     ]
    }
   ],
   "source": [
    "print(f\"THE {len(FEATURES)} BASIC FEATURES ARE:\")\n",
    "for c in FEATURES:\n",
    "    ftype = \"numerical\"\n",
    "    if combined[c].dtype==\"object\":\n",
    "        CATS.append(c)\n",
    "        combined[c] = combined[c].fillna(\"NAN\")\n",
    "        combined[c],_ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        ftype = \"categorical\"\n",
    "    if combined[c].dtype==\"int64\":\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "    elif combined[c].dtype==\"float64\":\n",
    "        combined[c] = combined[c].astype(\"float32\")\n",
    "        \n",
    "    n = combined[c].nunique()\n",
    "    print(f\"{c} ({ftype}) with {n} unique values\")\n",
    "    if n>=25: HIGH_CARDINALITY.append(c)\n",
    "    \n",
    "train = combined.iloc[:len(train)].copy()\n",
    "test = combined.iloc[len(train):].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_line_model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='RMSE', eval_metric='RMSE', random_state=SEED, verbose=0)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for tr_idx, va_idx in kf.split(train):\n",
    "    tr_x, va_x = train[FEATURES].iloc[tr_idx], train[FEATURES].iloc[va_idx]\n",
    "    tr_y, va_y = train['y'].iloc[tr_idx], train['y'].iloc[va_idx]\n",
    "    \n",
    "    tr_x = pd.get_dummies(tr_x, columns=CATS)\n",
    "    va_x = pd.get_dummies(va_x, columns=CATS)\n",
    "    \n",
    "    base_line_model.fit(tr_x, tr_y, eval_set=[(va_x, va_y)], early_stopping_rounds=100, verbose=0)\n",
    "    oof[va_idx] = base_line_model.predict(va_x)\n",
    "    predictions += base_line_model.predict(pd.get_dummies(test.drop(columns=['y']), columns=CATS))/kf.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['base_line'] = oof\n",
    "test['base_line'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([pd.get_dummies(train.drop(columns=['y']), columns=CATS), train['y']], axis=1)\n",
    "test = pd.concat([pd.get_dummies(test.drop(columns=['y']), columns=CATS), test['y']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3490316767298298\n"
     ]
    }
   ],
   "source": [
    "FOLD = 20\n",
    "kf = KFold(n_splits=FOLD, shuffle=True, random_state=SEED)\n",
    "oof = np.zeros(len(train))\n",
    "test_preds = np.zeros(len(test))\n",
    "all_score = 0\n",
    "for trn_idx, val_idx in kf.split(train):\n",
    "    _train = train.iloc[trn_idx].copy()\n",
    "    _valid = train.iloc[val_idx].copy()\n",
    "\n",
    "    model = LGBMRegressor(verbose=0)\n",
    "    model.fit(_train.drop(columns=['y']), _train.y, \n",
    "              eval_set=(_valid.drop(columns=['y']), _valid.y)\n",
    "              )\n",
    "    oof[val_idx] = model.predict(_valid.drop(columns=['y']))\n",
    "    test_preds += (model.predict(test[_train.drop(columns=['y']).columns]))\n",
    "    score = root_mean_squared_error((_valid.y), (model.predict(_valid.drop(columns=['y']))))\n",
    "    all_score += score\n",
    "test_preds /= FOLD\n",
    "print(all_score / FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3590253124957299\n"
     ]
    }
   ],
   "source": [
    "FOLD = 20\n",
    "kf = KFold(n_splits=FOLD, shuffle=True, random_state=SEED)\n",
    "oof = np.zeros(len(train))\n",
    "test_preds = np.zeros(len(test))\n",
    "all_score = 0\n",
    "for trn_idx, val_idx in kf.split(train):\n",
    "    _train = train.iloc[trn_idx].copy()\n",
    "    _valid = train.iloc[val_idx].copy()\n",
    "\n",
    "    model = LGBMRegressor(verbose=0)\n",
    "    model.fit(_train.drop(columns=['y']), _train.y, \n",
    "            #   eval_set=(_valid.drop(columns=['y']), _valid.y)\n",
    "              )\n",
    "    oof[val_idx] = model.predict(_valid.drop(columns=['y']))\n",
    "    test_preds += (model.predict(test[_train.drop(columns=['y']).columns]))\n",
    "    score = root_mean_squared_error((_valid.y), (model.predict(_valid.drop(columns=['y']))))\n",
    "    all_score += score\n",
    "test_preds /= FOLD\n",
    "print(all_score / FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 5, 100),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 100.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 100.0),\n",
    "        'random_state': SEED,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(**params)\n",
    "    oof = np.zeros(len(train))\n",
    "    for trn_idx, val_idx in kf.split(train):\n",
    "        _train = train.iloc[trn_idx].copy()\n",
    "        _valid = train.iloc[val_idx].copy()\n",
    "        model.fit(_train.drop(columns=['y']), _train.y)\n",
    "        oof[val_idx] = model.predict(_valid.drop(columns=['y']))\n",
    "    score = root_mean_squared_error(train.y, oof)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['가격(백만원)'] = test_preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
